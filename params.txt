

bs = 1  #batch size
d_in = 363
h1 = 1024   #neurons in first hidden layer
h2 = 2048   #nuerons in second hidden layer
h2p = 2048  #nuerons in second hidden layer of policy network
h2e = 512   #neurons in second hidden layer of evaluation network
d_out = 4096 #without including under promotions. otherwise we have to increase

#splitting the giraffe's feature vector to be input to the network
global_features = 17
## the following constitute the global features:
# side to move = 1
# castling rights = 4
# material configuration = 12
piece_centric = 218
## the following constitute the piece-centric features:
# piece lists with their properties = 2*(1+1+2+2+2+8)*5 = 160
# sldiing pieces mobility = 2*(8+4+4+4+4) = 48
# And, I just added extra 10 because, otherwise they are not adding up to 363. Someone pls recheck this.
square_centric = 128
## the following constitute the square-centric features:
# attack map = 64
# defend map = 64
h1a = 32 #no.of first set of neurons in first hidden layer
h1b = 512 #no.of second set of neurons in first hidden layer
h1c = 480 #no.of third set of neurons in first hidden layer

# x is your 363-dimensional input. and y is our output. We are randomly initializing them here.
x = Variable(torch.randn(bs, d_in))
y = Variable(torch.randn(bs, d_out), requires_grad=False)

model = PolicyNetwork_Full(d_in, h1, h2, d_out)
model2 = PolicyNetwork_Giraffe(d_in, global_features, piece_centric, square_centric, h1a, h2a, h3a, h2, d_out)
model3 = PolicyValNetwork_Full(d_in, h1, h2p, h2e, d_out)
